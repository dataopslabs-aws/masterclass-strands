{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847d1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "\n",
    "# Create an agent with the default model (Claude 3.7 Sonnet on Bedrock)\n",
    "agent = Agent()\n",
    "\n",
    "# This is equivalent to:\n",
    "agent = Agent(model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0a769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me calculate these for you:\n",
      "\n",
      "1) 1234 × 5678 = 7,006,652\n",
      "\n",
      "2) Square root of 1444 = 38"
     ]
    }
   ],
   "source": [
    "# Ask the agent a complex multi-part question involving reasoning, computation, and real-time awareness\n",
    "response = agent(\n",
    "\"What is 1234 multiplied by 5678, what is the square root of 1444\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22876d02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb923644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# Create a BedrockModel with custom configuration\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    region_name='us-east-1',\n",
    "    temperature=0.3,  # Lower temperature for more deterministic outputs\n",
    "    max_tokens=1024,  # Limit response length\n",
    "    # Optional: custom Bedrock client\n",
    "    client=boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    ")\n",
    "\n",
    "# Create an agent with the custom model configuration\n",
    "agent = Agent(model=bedrock_model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80291df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll convert these measurements for you:\n",
      "\n",
      "1) Converting 100°F to Celsius:\n",
      "   °C = (°F - 32) × 5/9\n",
      "   °C = (100 - 32) × 5/9\n",
      "   °C = 68 × 5/9\n",
      "   °C = 37.78°C\n",
      "\n",
      "2) Converting 5 kilometers to miles:\n",
      "   1 kilometer = 0.621371 miles\n",
      "   5 kilometers = 5 × 0.621371 miles\n",
      "   5 kilometers = 3.11 miles\n",
      "\n",
      "So 100°F equals 37.78°C, and 5 kilometers equals 3.11 miles."
     ]
    }
   ],
   "source": [
    "response = agent(\n",
    "\"Convert 100°F to Celsius, and then convert 5 kilometers to miles.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e3e33f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: strands-agents[litellm] in ./.venv/lib/python3.11/site-packages (0.1.6)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in ./.venv/lib/python3.11/site-packages (from strands-agents[litellm]) (1.38.31)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in ./.venv/lib/python3.11/site-packages (from strands-agents[litellm]) (1.38.31)\n",
      "Requirement already satisfied: docstring-parser<0.16.0,>=0.15 in ./.venv/lib/python3.11/site-packages (from strands-agents[litellm]) (0.15)\n",
      "Requirement already satisfied: mcp<2.0.0,>=1.8.0 in ./.venv/lib/python3.11/site-packages (from strands-agents[litellm]) (1.9.3)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.30.0 in ./.venv/lib/python3.11/site-packages (from strands-agents[litellm]) (1.34.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0 in ./.venv/lib/python3.11/site-packages (from strands-agents[litellm]) (1.34.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.30.0 in ./.venv/lib/python3.11/site-packages (from strands-agents[litellm]) (1.34.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from strands-agents[litellm]) (2.11.5)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in ./.venv/lib/python3.11/site-packages (from strands-agents[litellm]) (4.14.0)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in ./.venv/lib/python3.11/site-packages (from strands-agents[litellm]) (6.0.0)\n",
      "Collecting litellm<2.0.0,>=1.69.0 (from strands-agents[litellm])\n",
      "  Obtaining dependency information for litellm<2.0.0,>=1.69.0 from https://files.pythonhosted.org/packages/d0/1d/40a3f5d7c7a91b4aafce4b516e14eaef64d0f9ac7d9852560757bb074b97/litellm-1.72.2-py3-none-any.whl.metadata\n",
      "  Downloading litellm-1.72.2-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./.venv/lib/python3.11/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[litellm]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in ./.venv/lib/python3.11/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[litellm]) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./.venv/lib/python3.11/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[litellm]) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in ./.venv/lib/python3.11/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[litellm]) (2.4.0)\n",
      "Collecting aiohttp (from litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/ec/3e/d2e3f6864ca88f8b91afb20558fdcd43e11224fc4b4aad2103f05f37c98f/aiohttp-3.12.9-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading aiohttp-3.12.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (8.2.1)\n",
      "Requirement already satisfied: httpx>=0.23.0 in ./.venv/lib/python3.11/site-packages (from litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in ./.venv/lib/python3.11/site-packages (from litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (8.7.0)\n",
      "Collecting jinja2<4.0.0,>=3.1.2 (from litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for jinja2<4.0.0,>=3.1.2 from https://files.pythonhosted.org/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl.metadata\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for jsonschema<5.0.0,>=4.22.0 from https://files.pythonhosted.org/packages/a2/3d/023389198f69c722d039351050738d6755376c8fd343e91dc493ea485905/jsonschema-4.24.0-py3-none-any.whl.metadata\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting openai>=1.68.2 (from litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for openai>=1.68.2 from https://files.pythonhosted.org/packages/2a/10/f245db006a860dbc1f2e2c8382e0a1762c7753e7971ba43a1dc3f3ec1404/openai-1.84.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.84.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in ./.venv/lib/python3.11/site-packages (from litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (1.1.0)\n",
      "Collecting tiktoken>=0.7.0 (from litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for tiktoken>=0.7.0 from https://files.pythonhosted.org/packages/3f/86/55d9d1f5b5a7e1164d0f1538a85529b5fcba2b105f92db3622e5d7de6522/tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting tokenizers (from litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for tokenizers from https://files.pythonhosted.org/packages/ae/1a/4526797f3719b0287853f12c5ad563a9be09d446c44ac784cdd7c50f76ab/tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: anyio>=4.5 in ./.venv/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents[litellm]) (4.9.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in ./.venv/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents[litellm]) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in ./.venv/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents[litellm]) (2.9.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in ./.venv/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents[litellm]) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in ./.venv/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents[litellm]) (2.3.6)\n",
      "Requirement already satisfied: starlette>=0.27 in ./.venv/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents[litellm]) (0.47.0)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in ./.venv/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents[litellm]) (0.34.3)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents[litellm]) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents[litellm]) (1.34.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents[litellm]) (1.34.0)\n",
      "Requirement already satisfied: requests~=2.7 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents[litellm]) (2.32.3)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-proto==1.34.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents[litellm]) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.30.0->strands-agents[litellm]) (0.55b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents[litellm]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents[litellm]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents[litellm]) (0.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.8.0->strands-agents[litellm]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.8.0->strands-agents[litellm]) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (3.22.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/6c/30/316d194b093cde57d448a4c3209f22e3046c5bb2fb0820b118292b334be7/MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for attrs>=22.2.0 from https://files.pythonhosted.org/packages/77/06/bb80f5f86020c4551da315d78b3ab75e8228f89f0162f2c3a819e407941a/attrs-25.3.0-py3-none-any.whl.metadata\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for jsonschema-specifications>=2023.03.6 from https://files.pythonhosted.org/packages/01/0e/b27cdbaccf30b890c40ed1da9fd4a3593a5cf94dae54fb34f8a4b74fcd3f/jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/c1/b1/3baf80dc6d2b7bc27a95a67752d0208e410351e3feb4eb78de5f77454d8d/referencing-0.36.2-py3-none-any.whl.metadata\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for rpds-py>=0.7.1 from https://files.pythonhosted.org/packages/7a/58/deef4d30fcbcbfef3b6d82d17c64490d5c94585a2310544ce8e2d3024f83/rpds_py-0.25.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading rpds_py-0.25.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.68.2->litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai>=1.68.2->litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (0.10.0)\n",
      "Collecting tqdm>4 (from openai>=1.68.2->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for tqdm>4 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m183.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.29.0->strands-agents[litellm]) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.30.0->strands-agents[litellm]) (3.4.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.7.0->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/c5/1b/f0e4d13e6adf866ce9b069e191f303a30ab1277e037037a365c3aad5cc9c/regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m169.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.5.0 (from aiohttp->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for aiohappyeyeballs>=2.5.0 from https://files.pythonhosted.org/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/ec/6a/bc7e17a3e87a2985d3e8f4da4cd0f481060eb78fb08596c42be62c90a4d9/aiosignal-1.3.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/ec/a7/bffc1c7089812d432787f5539d59a18298ff1b43c3ac6d9134cb69eba7ab/frozenlist-1.6.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading frozenlist-1.6.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (17 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/26/b4/91fead447ccff56247edc7f0535fbf140733ae25187a33621771ee598a18/multidict-6.4.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading multidict-6.4.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for propcache>=0.2.0 from https://files.pythonhosted.org/packages/e2/c8/b649ed972433c3f0d827d7f0cf9ea47162f4ef8f4fe98c5f3641a0bc63ff/propcache-0.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading propcache-0.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for yarl<2.0,>=1.17.0 from https://files.pythonhosted.org/packages/ad/17/9b64e575583158551b72272a1023cdbd65af54fe13421d856b2850a6ddb7/yarl-1.20.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading yarl-1.20.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m114.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4 (from tokenizers->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/67/8b/222140f3cfb6f17b0dd8c4b9a0b36bd4ebefe9fb0098ba35d6960abcda0f/huggingface_hub-0.32.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.32.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/4d/36/2a115987e2d8c300a974597416d9de88f2444426de9571f4b59b2cca3acc/filelock-3.18.0-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/bb/61/78c7b3851add1481b048b5fdc29067397a1784e2910592bc81bb3f608635/fsspec-2025.5.1-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.69.0->strands-agents[litellm]) (25.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for pyyaml>=5.1 from https://files.pythonhosted.org/packages/8b/62/b9faa998fd185f65c1371643678e4d58254add437edb764a08c5a98fb986/PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.69.0->strands-agents[litellm])\n",
      "  Obtaining dependency information for hf-xet<2.0.0,>=1.1.2 from https://files.pythonhosted.org/packages/78/07/6ef50851b5c6b45b77a6e018fa299c69a2db3b8bbd0d5af594c0238b1ceb/hf_xet-1.1.3-cp37-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading hf_xet-1.1.3-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Downloading litellm-1.72.2-py3-none-any.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m187.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hUsing cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m221.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.84.0-py3-none-any.whl (725 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.5/725.5 kB\u001b[0m \u001b[31m235.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m197.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.9-cp311-cp311-macosx_11_0_arm64.whl (468 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.4/468.4 kB\u001b[0m \u001b[31m200.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m205.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.6.2-cp311-cp311-macosx_11_0_arm64.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m165.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.32.4-py3-none-any.whl (512 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.1/512.1 kB\u001b[0m \u001b[31m183.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading multidict-6.4.4-cp311-cp311-macosx_11_0_arm64.whl (37 kB)\n",
      "Downloading propcache-0.3.1-cp311-cp311-macosx_11_0_arm64.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m401.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.6/284.6 kB\u001b[0m \u001b[31m206.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rpds_py-0.25.1-cp311-cp311-macosx_11_0_arm64.whl (359 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.1/359.1 kB\u001b[0m \u001b[31m141.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m298.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.20.0-cp311-cp311-macosx_11_0_arm64.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m151.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m89.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.3-cp37-abi3-macosx_11_0_arm64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m169.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m78.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: tqdm, rpds-py, regex, pyyaml, propcache, multidict, MarkupSafe, hf-xet, fsspec, frozenlist, filelock, attrs, aiohappyeyeballs, yarl, tiktoken, referencing, jinja2, huggingface-hub, aiosignal, tokenizers, openai, jsonschema-specifications, aiohttp, jsonschema, litellm\n",
      "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.6.1 aiohttp-3.12.9 aiosignal-1.3.2 attrs-25.3.0 filelock-3.18.0 frozenlist-1.6.2 fsspec-2025.5.1 hf-xet-1.1.3 huggingface-hub-0.32.4 jinja2-3.1.6 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 litellm-1.72.2 multidict-6.4.4 openai-1.84.0 propcache-0.3.1 pyyaml-6.0.2 referencing-0.36.2 regex-2024.11.6 rpds-py-0.25.1 tiktoken-0.9.0 tokenizers-0.21.1 tqdm-4.67.1 yarl-1.20.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install 'strands-agents[litellm]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36429f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c96b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models.litellm import LiteLLMModel\n",
    "\n",
    "# First install the required package\n",
    "# pip install strands-agents[litellm]\n",
    "\n",
    "# Create a LiteLLM model for OpenAI\n",
    "litellm_model = LiteLLMModel(\n",
    "    client_args={\n",
    "        \"api_key\": \"sk-proj-*\",\n",
    "    },\n",
    "    model_id=\"gpt-4o\",\n",
    "    params={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 1024\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create an agent with the OpenAI model via LiteLLM\n",
    "agent = Agent(model=litellm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3874ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering the AI productivity tools space with a $10M funding is an exciting opportunity. Here's a detailed go-to-market plan, pricing model, and key technical differentiators to consider:\n",
      "\n",
      "### Go-to-Market Plan\n",
      "\n",
      "1. **Market Research and Positioning:**\n",
      "   - **Identify Target Audience:** Focus on professionals, teams, and enterprises seeking enhanced productivity through AI. Identify specific sectors like tech, finance, and education that can benefit significantly.\n",
      "   - **Competitive Analysis:** Study Notion AI and Microsoft Copilot to understand their strengths and weaknesses. Identify gaps and areas for differentiation.\n",
      "   - **Unique Value Proposition (UVP):** Develop a compelling UVP that highlights how your tool improves productivity, integrates seamlessly with existing workflows, and offers unique features.\n",
      "\n",
      "2. **Product Development and Testing:**\n",
      "   - **MVP Launch:** Develop a Minimum Viable Product (MVP) with core features. Gather feedback from beta testers and iterate based on their input.\n",
      "   - **AI Capabilities:** Ensure robust AI capabilities such as natural language processing, machine learning, and predictive analytics.\n",
      "\n",
      "3. **Marketing and Promotion:**\n",
      "   - **Content Marketing:** Create educational content, case studies, and webinars to demonstrate the tool's capabilities and benefits.\n",
      "   - **Partnerships and Collaborations:** Partner with other tech companies, productivity platforms, and influencers to expand reach.\n",
      "   - **Launch Campaigns:** Use social media, email marketing, and paid advertising to create buzz around the launch.\n",
      "\n",
      "4. **Sales Strategy:**\n",
      "   - **Freemium Model:** Offer a free version with basic features to attract users. Provide premium features in a paid version to convert free users.\n",
      "   - **Direct Sales:** Develop a sales team to target enterprise clients and offer customized solutions.\n",
      "\n",
      "5. **Customer Support and Feedback Loop:**\n",
      "   - **Customer Service:** Provide excellent customer support to build trust and loyalty.\n",
      "   - **Feedback Mechanism:** Implement a system for continuous feedback to improve the product.\n",
      "\n",
      "### Pricing Model\n",
      "\n",
      "1. **Freemium Model:**\n",
      "   - Offer a free tier with essential features to attract individual users and small teams.\n",
      "   - Provide tiered pricing for premium features based on the size of the team or organization. For example:\n",
      "     - **Basic Plan:** $10/user/month for additional features like enhanced AI capabilities.\n",
      "     - **Pro Plan:** $20/user/month for advanced integrations and analytics.\n",
      "     - **Enterprise Plan:** Custom pricing for large organizations with personalized support and customization.\n",
      "\n",
      "2. **Discounts and Incentives:**\n",
      "   - Offer discounts for annual subscriptions to encourage long-term commitments.\n",
      "   - Provide special pricing for educational institutions and non-profits.\n",
      "\n",
      "### Key Technical Differentiators\n",
      "\n",
      "1. **Advanced AI Features:**\n",
      "   - **Contextual Understanding:** Develop AI that understands context better to provide more relevant suggestions and automation.\n",
      "   - **Multimodal Capabilities:** Enable the tool to process and integrate text, images, and voice inputs seamlessly.\n",
      "\n",
      "2. **Seamless Integration:**\n",
      "   - Ensure compatibility with popular productivity tools like Slack, Trello, and Asana. Provide APIs for custom integrations.\n",
      "\n",
      "3. **User Experience and Interface:**\n",
      "   - Focus on a user-friendly interface with intuitive design and easy navigation.\n",
      "   - Implement customization options for users to tailor the tool to their specific needs.\n",
      "\n",
      "4. **Security and Privacy:**\n",
      "   - Prioritize data security and privacy with robust encryption and compliance with regulations like GDPR.\n",
      "\n",
      "5. **Scalability and Performance:**\n",
      "   - Build a scalable architecture to support growing user numbers without compromising on performance.\n",
      "\n",
      "By focusing on these strategies and differentiators, your startup can effectively compete with established players like Notion AI and Microsoft Copilot in the AI productivity tools space."
     ]
    }
   ],
   "source": [
    "response = agent(\n",
    "    \"You're advising a startup with $10M funding, entering the AI productivity tools space. Given current trends, outline a go-to-market plan, suggest a pricing model, and identify key technical differentiators needed to compete with Notion AI and Microsoft Copilot.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f73966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: strands-agents[ollama]\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install strands-agents[ollama] --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45634905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models.ollama import OllamaModel\n",
    "\n",
    "# First install the required package\n",
    "# pip install strands-agents[ollama]\n",
    "\n",
    "# Create an Ollama model (requires Ollama running locally)\n",
    "ollama_model = OllamaModel(\n",
    "    host=\"http://localhost:11434\",  # Ollama server address\n",
    "    model_id=\"gemma3\",  # Specify which model to use\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# Create an agent with the local Ollama model\n",
    "agent = Agent(model=ollama_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a06865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let’s break down the differences between Supervised, Unsupervised, and Reinforcement Learning – they’re all approaches to training machine learning models, but they tackle problems in fundamentally different ways.\n",
      "\n",
      "**1. Supervised Learning:**\n",
      "\n",
      "* **Concept:** Think of it like learning with a teacher. You provide the algorithm with labeled data – meaning you give it both the *input* and the *correct output*.\n",
      "* **Data:** Labeled data – examples with known answers. (e.g., images of cats and dogs labeled as “cat” or “dog”, customer data with purchase history labeled as “likely to buy” or “unlikely to buy”).\n",
      "* **Goal:** The algorithm learns a mapping function that predicts the output based on the input.\n",
      "* **Examples:**\n",
      "    * **Image Classification:** Identifying objects in images.\n",
      "    * **Spam Detection:** Classifying emails as spam or not spam.\n",
      "    * **Predicting House Prices:** Based on features like size, location, etc.\n",
      "* **Key Phrase:** “Learning *from* labeled data.”\n",
      "\n",
      "\n",
      "**2. Unsupervised Learning:**\n",
      "\n",
      "* **Concept:**  The algorithm is given *unlabeled* data and must discover patterns and structures on its own. It's like exploring a new territory without a map.\n",
      "* **Data:** Unlabeled data – just the inputs.\n",
      "* **Goal:** The algorithm identifies hidden patterns, clusters, or reduces the dimensionality of the data.\n",
      "* **Examples:**\n",
      "    * **Customer Segmentation:** Grouping customers based on their behavior.\n",
      "    * **Anomaly Detection:** Identifying unusual data points (e.g., fraudulent transactions).\n",
      "    * **Dimensionality Reduction:** Simplifying complex data by reducing the number of variables.\n",
      "* **Key Phrase:** “Discovering *patterns* in unlabeled data.”\n",
      "\n",
      "\n",
      "\n",
      "**3. Reinforcement Learning:**\n",
      "\n",
      "* **Concept:** This is like training a dog with rewards and punishments. The algorithm (called an “agent”) learns by interacting with an environment and receiving feedback in the form of rewards for good actions and penalties for bad ones.\n",
      "* **Environment:** The agent interacts with a simulated or real environment.\n",
      "* **Agent:** The learning algorithm.\n",
      "* **Reward Signal:**  A numerical value that indicates the quality of the agent’s action.\n",
      "* **Goal:** The agent learns a policy – a strategy – that maximizes its cumulative reward over time.\n",
      "* **Examples:**\n",
      "    * **Game Playing (AlphaGo):** Training an AI to play games like Go.\n",
      "    * **Robotics:**  Teaching a robot to walk or perform tasks.\n",
      "    * **Resource Management:** Optimizing resource allocation.\n",
      "* **Key Phrase:** “Learning *through* interaction and reward.”\n",
      "\n",
      "**Here's a table summarizing the key differences:**\n",
      "\n",
      "| Feature           | Supervised Learning | Unsupervised Learning | Reinforcement Learning |\n",
      "|--------------------|----------------------|-----------------------|-------------------------|\n",
      "| **Data**           | Labeled             | Unlabeled             | Interaction & Reward    |\n",
      "| **Goal**           | Predict Output       | Discover Patterns      | Maximize Reward         |\n",
      "| **Feedback**       | Correct Answers      | None                   | Reward/Penalty          |\n",
      "| **Typical Use Cases**| Classification, Regression | Clustering, Dimensionality Reduction | Game Playing, Robotics |\n",
      "\n",
      "\n",
      "\n",
      "Do you want me to delve deeper into any of these types of learning, or perhaps provide a specific example of how each is used in a particular industry?"
     ]
    }
   ],
   "source": [
    "response = agent(\n",
    "    \"Explain the difference between supervised,unsupervised learning and Reinforcement Learning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e62a14c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local Ollama model\n"
     ]
    }
   ],
   "source": [
    "from strands import Agent\n",
    "from strands.models.ollama import OllamaModel\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# Step 1: Define the local Ollama model (preferred)\n",
    "local_model = OllamaModel(\n",
    "    host=\"http://localhost:11434\",\n",
    "    model_id=\"gemma3\",  # Replace with your local model name\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# Step 2: Define the fallback Bedrock model\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "# Step 3: Attempt to use the local model first; fallback to Bedrock if it fails\n",
    "try:\n",
    "    # Try initializing the agent with the local model\n",
    "    agent = Agent(model=local_model)\n",
    "    print(\"Using local Ollama model\")\n",
    "except Exception as e:\n",
    "    print(f\"Local model failed: {e}\")\n",
    "    print(\"Falling back to Bedrock model\")\n",
    "    agent = Agent(model=bedrock_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84387f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down the differences between AWS SNS (Simple Notification Service) and AWS SQS (Simple Queue Service). They're both core AWS services for decoupling and distributing messages, but they serve different purposes and have distinct characteristics.\n",
      "\n",
      "**1. AWS SNS (Simple Notification Service)**\n",
      "\n",
      "* **Purpose:** SNS is a **publish/subscribe messaging service**. It's designed for sending notifications to multiple subscribers. Think of it like a broadcast system.\n",
      "* **How it Works:**\n",
      "    * **Publishers:** Applications or services send messages to an SNS topic.\n",
      "    * **Subscribers:**  These can be email addresses, SMS messages, HTTP/HTTPS endpoints, AWS Lambda functions, or even other AWS services.\n",
      "    * **Routing:** SNS routes the message to all of its subscribers.\n",
      "* **Key Features:**\n",
      "    * **Fan-out:**  The core strength – easily send a single message to many recipients.\n",
      "    * **Filtering:** Subscribers can filter messages based on attributes (key-value pairs) within the message. This allows you to target specific subscribers with specific content.\n",
      "    * **Delivery Types:** Supports different delivery methods (email, SMS, HTTP/HTTPS).\n",
      "    * **Scalability:**  Handles a massive number of messages and subscribers.\n",
      "* **Use Cases:**\n",
      "    * **Mobile App Notifications:** Sending push notifications to users.\n",
      "    * **Emergency Alerts:** Broadcasting critical information during emergencies.\n",
      "    * **Marketing Campaigns:** Sending promotional emails.\n",
      "    * **System Alerts:** Notifying administrators of system issues.\n",
      "\n",
      "\n",
      "**2. AWS SQS (Simple Queue Service)**\n",
      "\n",
      "* **Purpose:** SQS is a **message queuing service**. It's designed for decoupling applications and ensuring reliable message delivery.\n",
      "* **How it Works:**\n",
      "    * **Producers:** Applications or services put messages into a queue.\n",
      "    * **Consumers:** Applications or services retrieve messages from the queue.  Only *one* consumer typically processes a message at a time (though you can configure multiple consumers for parallel processing).\n",
      "    * **Decoupling:** Producers don't need to know anything about the consumers. They simply send messages to the queue.\n",
      "* **Key Features:**\n",
      "    * **Reliability:** SQS guarantees message delivery – messages are not lost if a consumer is temporarily unavailable.\n",
      "    * **Scalability:** Handles a large volume of messages.\n",
      "    * **FIFO Queues:**  Supports First-In, First-Out (FIFO) queues for strict ordering requirements.\n",
      "    * **Visibility Timeout:**  Allows consumers to temporarily \"hide\" a message while they're processing it, preventing other consumers from immediately picking it up.\n",
      "* **Use Cases:**\n",
      "    * **Background Processing:** Offloading long-running tasks from web applications.\n",
      "    * **Microservices Communication:**  Enabling asynchronous communication between microservices.\n",
      "    * **Order Processing:**  Handling orders in an e-commerce system.\n",
      "    * **Data Ingestion:**  Buffering data for processing.\n",
      "\n",
      "\n",
      "\n",
      "**Here's a table summarizing the key differences:**\n",
      "\n",
      "| Feature          | AWS SNS                        | AWS SQS                       |\n",
      "|------------------|---------------------------------|-------------------------------|\n",
      "| **Purpose**       | Publish/Subscribe (Fan-out)     | Message Queuing (Decoupling) |\n",
      "| **Architecture**  | Publisher -> Topic -> Subscribers | Producer -> Queue -> Consumer |\n",
      "| **Delivery Model**| Broadcast to multiple recipients| Single consumer processes one message |\n",
      "| **Primary Use**   | Notifications, Broadcasting     | Decoupling, Reliability      |\n",
      "| **Ordering**      | Not guaranteed                  | Guaranteed (FIFO queues)      |\n",
      "| **Complexity**    | Generally simpler to set up     | Can be more complex depending on configuration |\n",
      "\n",
      "\n",
      "\n",
      "**When to Use Which?**\n",
      "\n",
      "* **Use SNS when:** You need to send a single message to a group of recipients and don't care about the order in which they receive it.\n",
      "* **Use SQS when:** You need to decouple applications, ensure reliable message delivery, and handle asynchronous processing.\n",
      "\n",
      "**Can they be used together?**\n",
      "\n",
      "Absolutely! They are often used together. For example:\n",
      "\n",
      "* A web application might publish a message to an SNS topic (e.g., \"Order Created\").\n",
      "* The SNS topic then routes the message to an SQS queue.\n",
      "* Multiple worker services (consumers) pull messages from the SQS queue to process the order.\n",
      "\n",
      "---\n",
      "\n",
      "Do you want me to delve deeper into a specific aspect, such as:\n",
      "\n",
      "*   Configuration examples?\n",
      "*   Cost considerations?\n",
      "*   How they integrate with other AWS services (Lambda, API Gateway, etc.)?"
     ]
    }
   ],
   "source": [
    "response = agent(\n",
    "    \"Explain the difference between AWS SNS vs AWS SQS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c3e3e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(99145) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/1b/cc/0af9c07f8d714ea563b12383a7e5bde9479cf32413ee2f346a9c5a801f22/pandas-2.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pandas-2.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.23.2 (from pandas)\n",
      "  Obtaining dependency information for numpy>=1.23.2 from https://files.pythonhosted.org/packages/29/6b/2d31da8e6d2ec99bed54c185337a87f8fbeccc1cd9804e38217e92f3f5e2/numpy-2.3.0-cp311-cp311-macosx_14_0_arm64.whl.metadata\n",
      "  Downloading numpy-2.3.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.0-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.0-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.3.0 pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b457a6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Obtaining dependency information for tabulate from https://files.pythonhosted.org/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de11024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "# AI Productivity Tools Startup: Go-to-Market Strategy\n",
      "\n",
      "## Market Analysis\n",
      "The AI productivity tools space is crowded but still evolving rapidly, with major players like Notion AI and Microsoft Copilot having established strong positions through existing distribution channels. However, opportunities exist for a well-funded startup that can deliver superior user experience and more specialized functionality.\n",
      "\n",
      "## Go-to-Market Strategy\n",
      "\n",
      "### Phase 1: Focus & Differentiation (Months 0-3)\n",
      "- **Target specific vertical**: Rather than competing broadly, focus on knowledge workers in a specific industry (e.g., legal, healthcare, or research) where existing solutions fall short\n",
      "- **Build deep domain expertise**: Train models on industry-specific data and workflows\n",
      "- **Develop 2-3 core \"wow\" features** that dramatically outperform incumbents for this vertical\n",
      "\n",
      "### Phase 2: Limited Release (Months 3-6)\n",
      "- Launch invite-only beta with 50-100 influential users in target vertical\n",
      "- Collect intensive user feedback and iterate rapidly\n",
      "- Document clear ROI metrics and testimonials\n",
      "- Develop content highlighting user success stories\n",
      "\n",
      "### Phase 3: Vertical Expansion (Months 6-12)\n",
      "- Open access within target vertical\n",
      "- Implement referral program incentivizing existing users\n",
      "- Develop API/integration ecosystem specific to industry workflows\n",
      "- Begin building community through user events and content\n",
      "\n",
      "### Phase 4: Horizontal Expansion (Months 12+)\n",
      "- Expand to adjacent verticals leveraging learnings\n",
      "- Increase marketing spend for broader awareness\n",
      "- Pursue strategic partnerships with complementary tools\n",
      "\n",
      "## Pricing Model\n",
      "\n",
      "**Freemium + Tiered Subscription**:\n",
      "\n",
      "1. **Free tier**: Limited but valuable functionality to drive adoption\n",
      "   - Basic AI assistance features\n",
      "   - Usage caps (e.g., 25 AI queries/month)\n",
      "\n",
      "2. **Professional tier** ($20-30/month):\n",
      "   - Unlimited AI assistance\n",
      "   - Advanced domain-specific features\n",
      "   - Priority processing\n",
      "\n",
      "3. **Team/Enterprise tier** ($45-75/user/month):\n",
      "   - Admin controls, security features\n",
      "   - Collaborative AI workflows\n",
      "   - Custom model training options\n",
      "   - Dedicated support\n",
      "\n",
      "4. **API pricing**: Separate consumption-based pricing for developers\n",
      "\n",
      "**Key advantage**: Higher pricing than horizontal competitors justified by specialized vertical-specific capabilities that deliver measurable ROI.\n",
      "\n",
      "## Technical Differentiators\n",
      "\n",
      "1. **Context-aware collaboration**: Build AI that understands organizational context better than general tools by focusing on specific workflows\n",
      "   \n",
      "2. **Specialized knowledge**: Train on domain-specific data and terminology that general models lack\n",
      "\n",
      "3. **Workflow integration**: Create seamless connections with existing vertical-specific software tools\n",
      "\n",
      "4. **Transparency & control**: Provide more visibility and customization of AI reasoning than competitors, addressing trust concerns\n",
      "\n",
      "5. **Actionable intelligence**: Move beyond just generating content to providing analytical insights and recommendations specific to industry KPIs\n",
      "\n",
      "6. **Data sovereignty**: Offer stronger privacy guarantees than competitors, particularly important in regulated industries\n",
      "\n",
      "## Key Success Metrics\n",
      "- User activation rate within first 7 days\n",
      "- Time saved per user per week (measured by in-app tracking)\n",
      "- Conversion from free to paid\n",
      "- Net revenue retention (focus on expanding usage within accounts)\n",
      "- Feature-specific engagement metrics\n",
      "\n",
      "The $10M funding should be allocated approximately: 40% engineering, 30% go-to-market, 20% operations, and 10% contingency reserve.Okay, let's craft a go-to-market plan for a new AI productivity tool startup with $10M funding, aiming to compete in a crowded space like Notion AI and Microsoft Copilot. This needs to be ambitious, strategic, and focused on carving out a niche.\n",
      "\n",
      "**I. Go-to-Market Plan (6-18 Months)**\n",
      "\n",
      "* **Phase 1: Focused Beta & Early Adopter Program (Months 1-3):**\n",
      "    * **Target Audience:**  Specifically, **Marketing Agencies & Small Creative Teams** (graphic designers, copywriters, social media managers). These groups are *already* heavily reliant on productivity tools and are often early adopters of AI.\n",
      "    * **Product Focus:** Initially, concentrate on a *single* core AI feature – let’s say **AI-Powered Content Briefing & Outline Generation**. This is a high-value, immediately useful feature that addresses a common pain point.\n",
      "    * **Metrics:** Track feature usage, user onboarding completion rates, and initial user feedback.\n",
      "    * **Marketing:**  Targeted LinkedIn campaigns, content marketing focused on “AI for creative workflows,” and outreach to relevant industry influencers.\n",
      "\n",
      "\n",
      "* **Phase 2: Controlled Launch & Expansion (Months 4-12):**\n",
      "    * **Expand Target:**  Gradually expand to **Small Business Owners (SMBs) – particularly in SaaS & E-commerce.**  This offers a larger addressable market.\n",
      "    * **Feature Expansion:** Introduce a secondary AI feature – perhaps **AI-Powered Meeting Summaries & Action Item Extraction.**\n",
      "    * **Channel Strategy:**  Start exploring partnerships with complementary tools (CRM, project management software).  Consider affiliate marketing.\n",
      "    * **Community Building:**  Create a strong online community (Slack, Discord) to foster engagement and gather feedback.\n",
      "\n",
      "\n",
      "* **Phase 3: Scaling & Feature Velocity (Months 12-18):**\n",
      "    * **Broaden Target:**  Expand to broader SMBs and potentially larger teams.\n",
      "    * **Strategic Integrations:**  Deepen integrations with key productivity platforms (Google Workspace, Slack, Asana, etc.).\n",
      "    * **Premium Features:** Introduce tiered pricing with advanced features (e.g., brand voice customization, advanced analytics).\n",
      "\n",
      "\n",
      "\n",
      "**II. Pricing Model**\n",
      "\n",
      "Given the competitive landscape, a freemium model with tiered subscriptions is crucial.\n",
      "\n",
      "* **Free Tier:** Limited AI usage (e.g., 5-10 AI-generated briefs/outlines per month).  This acts as a powerful lead magnet.\n",
      "* **Starter ($15-25/month):**  Increased AI usage, basic reporting, and priority support.  Targeted at individual freelancers or small teams.\n",
      "* **Pro ($50-80/month):**  Unlimited AI usage, advanced reporting, brand voice customization, and dedicated support.  For growing teams.\n",
      "* **Enterprise (Custom Pricing):**  For larger organizations – volume discounts, custom integrations, and account management.\n",
      "\n",
      "**Key Pricing Considerations:**\n",
      "\n",
      "* **Value-Based Pricing:**  Price based on the *time saved* or *revenue generated* through AI assistance.  Quantify this in marketing materials.\n",
      "* **Competitive Analysis:**  Monitor Notion AI and Copilot pricing, but don’t simply match – justify your pricing with superior features or a more intuitive experience.\n",
      "\n",
      "\n",
      "\n",
      "**III. Technical Differentiators – Competing with the Giants**\n",
      "\n",
      "This is where you *must* stand out. Simply replicating Notion AI or Copilot’s features won’t be enough.\n",
      "\n",
      "1. **Specialized AI Models:**\n",
      "   * **Domain-Specific Training:** Don’t just use a general-purpose AI. Train your models on *specific* data sets relevant to marketing, creative workflows, or SMB operations. This will lead to significantly better outputs.\n",
      "   * **Brand Voice Learning:**  Go beyond simple tone adjustments.  Develop a system that *learns* and consistently replicates a brand’s unique voice and style.\n",
      "\n",
      "2. **Workflow Integration & Contextual Awareness:**\n",
      "   * **Deep Integration:**  Don’t just offer an AI button. Build a seamless workflow *within* the tools your target users already use.  For example, automatically populate a content brief directly into a design tool.\n",
      "   * **Contextual Understanding:**  The AI needs to understand the *entire* context of a project – not just the current task.  This requires robust data connection and processing.\n",
      "\n",
      "3. **User Experience (UX) – Intuitive & Delightful:**\n",
      "    * **Simplified Interface:**  Focus on a clean, intuitive interface that’s easy to learn and use – especially for non-technical users.\n",
      "    * **Human-in-the-Loop:**  Design the system to *augment* human creativity, not replace it.  Provide clear prompts and guidance.\n",
      "\n",
      "4. **Data Privacy & Security:**  This is *critical*.  Clearly articulate your data privacy policies and security measures.  Offer options for data residency.\n",
      "\n",
      "5. **Rapid Iteration & Feedback Loops:**  Establish a system for quickly incorporating user feedback and iterating on the product.  A fast-moving product will be more attractive than a polished but stagnant one.\n",
      "\n",
      "\n",
      "\n",
      "**Important Note:**  $10M is a significant amount of funding, but AI is a rapidly evolving space.  Prioritize agility, experimentation, and a laser focus on your chosen niche.  Don't be afraid to pivot if necessary.\n",
      "\n",
      "To help me refine this further, could you tell me:\n",
      "\n",
      "*   What specific industry or niche are you initially targeting (e.g., marketing agencies, SaaS startups, graphic designers)?\n",
      "*   What is the *primary* AI feature you're initially building?|    | Model                       | Response Preview                                                                                                                                                                                                |\n",
      "|---:|:----------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|  0 | GPT-4o (via LiteLLM)        | Error: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: sk-REPLA****************_KEY. You can find your API key at https://platform.openai.com/account/api-keys. |\n",
      "|  1 | Claude 3.5 Sonnet (Bedrock) | Error: An error occurred (ValidationException) when calling the ConverseStream operation: The provided model identifier is invalid.                                                                             |\n",
      "|  2 | Claude 3 Opus (Bedrock)     | Error: An error occurred (AccessDeniedException) when calling the ConverseStream operation: You don't have access to the model with the specified model ID.                                                     |\n",
      "|  3 | Claude 3.7 Sonnet (Bedrock) | Error: 'AgentResult' object is not subscriptable                                                                                                                                                                |\n",
      "|  4 | Local Gemma (via Ollama)    | Error: 'AgentResult' object is not subscriptable                                                                                                                                                                |\n"
     ]
    }
   ],
   "source": [
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from strands.models.ollama import OllamaModel\n",
    "from strands.models.litellm import LiteLLMModel\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "\n",
    "# Complex prompt for evaluation\n",
    "prompt = (\n",
    "    \"You're advising a startup with $10M funding, entering the AI productivity tools space. \"\n",
    "    \"Given current trends, outline a go-to-market plan, suggest a pricing model, and identify \"\n",
    "    \"key technical differentiators needed to compete with Notion AI and Microsoft Copilot.\"\n",
    ")\n",
    "\n",
    "# Define all models\n",
    "models = {\n",
    "    \"Claude 3.7 Sonnet (Bedrock)\": BedrockModel(\n",
    "        model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        region_name=\"us-west-2\"\n",
    "    ),\n",
    "    \"Claude 3.5 Sonnet (Bedrock)\": BedrockModel(\n",
    "        model_id=\"us.anthropic.claude-v2:1\",\n",
    "        region_name=\"us-west-2\"\n",
    "    ),\n",
    "    \"Claude 3 Opus (Bedrock)\": BedrockModel(\n",
    "        model_id=\"us.anthropic.claude-3-opus-20240229-v1:0\",\n",
    "        region_name=\"us-west-2\"\n",
    "    ),\n",
    "    \"GPT-4o (via LiteLLM)\": LiteLLMModel(\n",
    "        client_args={\"api_key\": \"sk-REPLACE_WITH_YOUR_API_KEY\"},\n",
    "        model_id=\"gpt-4o\",\n",
    "        params={\"temperature\": 0.5, \"max_tokens\": 1024}\n",
    "    ),\n",
    "    \"Local Gemma (via Ollama)\": OllamaModel(\n",
    "        host=\"http://localhost:11434\",\n",
    "        model_id=\"gemma3\",\n",
    "        temperature=0.3\n",
    "    )\n",
    "}\n",
    "\n",
    "# Function to run agent and get output\n",
    "def run_model(name, model):\n",
    "    try:\n",
    "        agent = Agent(model=model)\n",
    "        response = agent(prompt)\n",
    "        return name, response[:500]  # Limit output length for comparison\n",
    "    except Exception as e:\n",
    "        return name, f\"Error: {e}\"\n",
    "\n",
    "# Run all models concurrently\n",
    "results = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(run_model, name, model) for name, model in models.items()]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        results.append(future.result())\n",
    "\n",
    "# Create and display results table\n",
    "df = pd.DataFrame(results, columns=[\"Model\", \"Response Preview\"])\n",
    "print(df.to_markdown())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
